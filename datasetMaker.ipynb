{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility for creating a testing dataset by downloading memes and OCRing them with Google Vision API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I made a custom API for reddit meme feed that can be used to get around 2.5k newest memes from reddit\n",
    "# DO NOT use any params or query\n",
    "# Use only GET request method\n",
    "\n",
    "memeApiUri=\"https://meme-feed-api.vercel.app/api/getRedditMemes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memes are already downloaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import urllib.request\n",
    "import pytesseract\n",
    "\n",
    "# create memes dir if it doesnt exist\n",
    "memesFolder = \"memes\"\n",
    "if not os.path.exists(memesFolder):\n",
    "    os.makedirs(memesFolder)\n",
    "\n",
    "# Example API response:\n",
    "# [{\n",
    "# title\t\"Every Single Time\"\n",
    "# author\t\"Abschori\"\n",
    "# createdAt\t1663673918\n",
    "# fetchedAt\t1663689431254\n",
    "# contentUrl\t\"https://i.redd.it/qkz1jrr630p91.gif\"\n",
    "# id\t\"xj6fj8\"\n",
    "# likes\t6026\n",
    "# nsfw\tfalse\n",
    "# postLink\t\"https://www.reddit.com/râ€¦j6fj8/every_single_time/\"\n",
    "# provider\t\"r\"\n",
    "# subreddit\t\"dankmemes\"\n",
    "# },...]\n",
    "\n",
    "# Downloads 1000 OCRable memes to meme folder\n",
    "def downloadMemes():\n",
    "\n",
    "    # Get memes from API\n",
    "    response = requests.get(memeApiUri)\n",
    "    memes = json.loads(response.text)\n",
    "\n",
    "    # Filter out NSFW memes and .gifs\n",
    "    memes = [\n",
    "        meme\n",
    "        for meme in memes\n",
    "        if not meme[\"nsfw\"] and not meme[\"contentUrl\"].endswith(\".gif\")\n",
    "    ]\n",
    "\n",
    "    # sort by likes first, so we discard the bad ones\n",
    "    memes.sort(key=lambda x: x[\"likes\"], reverse=True)\n",
    "\n",
    "    # Download the memes and discard the ones that are not text based\n",
    "    for meme in memes:\n",
    "        # max out at 1000 memes\n",
    "        if len(os.listdir(memesFolder)) > 1000:\n",
    "            return 1\n",
    "\n",
    "        imageUrl = meme[\"contentUrl\"]\n",
    "        imageExtension = f\".{imageUrl.split('.')[-1]}\"\n",
    "        imagePath = f\"{memesFolder}/{meme['id']}{imageExtension}\"\n",
    "\n",
    "        # check if file already exists\n",
    "        if not os.path.exists(imagePath):\n",
    "            try:\n",
    "                # download the image\n",
    "                urllib.request.urlretrieve(imageUrl, imagePath)\n",
    "                memesInFolder = len(os.listdir(memesFolder))\n",
    "                print(f\"Downloaded to {imagePath} {memesInFolder}/{1000}\")\n",
    "                # check if it contains text\n",
    "                if not checkText(imagePath):\n",
    "                    print(f\"No text in {imagePath} -> removing\")\n",
    "                    os.remove(imagePath)\n",
    "            except:\n",
    "                print(f\"Failed to download {meme['id']}\")\n",
    "\n",
    "    return 1\n",
    "\n",
    "\n",
    "# Checks if an image contains text\n",
    "# This is used to filter out memes that are not text based, so there is less wasted API calls for Google Vision API\n",
    "# Uses Tesseract, as it seems to be faster than EasyOCR\n",
    "def checkText(imagePath):\n",
    "    text = pytesseract.image_to_string(imagePath)\n",
    "\n",
    "    if len(text) > 5:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "# Check if there is meme folder\n",
    "if len(os.listdir(\"memes\")) < 1000:\n",
    "    print(\"Downloading memes...\")\n",
    "    downloadMemes()\n",
    "else:\n",
    "    print(\"Memes are already downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the memes are downloaded, let's OCR them with Google Vision API to finalize the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup logger\n",
    "# @see https://stackoverflow.com/questions/6386698/how-to-write-to-a-file-using-the-logging-python-module\n",
    "import logging\n",
    "logging.basicConfig(filename=\"datasetMaker.log\",\n",
    "                    filemode='a',\n",
    "                    format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                    datefmt='%H:%M:%S',\n",
    "                    level=logging.DEBUG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from google.cloud import vision\n",
    "\n",
    "# load client\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"google_key.json\"\n",
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "# Parts of this function code are from https://cloud.google.com/vision/docs/ocr#vision_text_detection-python\n",
    "def detect_text(path):\n",
    "    logging.info(f\"Starting detection for {path}\")\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    # fetch\n",
    "    image = vision.Image(content=content)\n",
    "    response = client.text_detection(image=image)\n",
    "\n",
    "    logging.info(f\"response for {path}: {response}\")\n",
    "\n",
    "    if response.error.message:\n",
    "        logging.error(response.error.message)\n",
    "        raise Exception(f\"{response.error.message} for {path}. Stopping script\")\n",
    "    \n",
    "    return response.text_annotations[0].description\n",
    "\n",
    "# OCR all memes\n",
    "for meme in os.listdir(memesFolder):\n",
    "    if meme.endswith(\".txt\"):\n",
    "        continue    \n",
    "\n",
    "    # each meme gets its text result saved to a .txt file in the same folder\n",
    "    textPath = f\"{memesFolder}/{meme.split('.')[0]}.txt\"\n",
    "    if not os.path.exists(textPath):\n",
    "        try:\n",
    "            text = detect_text(f\"{memesFolder}/{meme}\")\n",
    "            with open(textPath, \"w\") as f:\n",
    "                f.write(text)\n",
    "            print(f\"Saved text to {textPath} with length {len(text)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to OCR {meme}\")\n",
    "            print(e)\n",
    "            raise e\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
